{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Daniel Lusk, University of Potsdam\n",
    "\n",
    "Inspired by: Ankit Kariryaa ([github repo](https://github.com/ankitkariryaa/An-unexpectedly-large-count-of-trees-in-the-western-Sahara-and-Sahel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "TODO: Write overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started\n",
    "\n",
    "TODO: Write getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "\n",
    "from config import Preprocessing\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import erosion\n",
    "from skimage.segmentation import find_boundaries\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import warnings  # ignore annoying warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Magic commands\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load configuration and get image directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Preprocessing.Config()\n",
    "im_dirs = glob.glob(os.path.join(config.data_dir_path, \"*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate and write NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_write_ndvi(d):\n",
    "    \"\"\"Takes an image directory, locates the RGBI image, calculates the corresponding\n",
    "    NDVI layer, and writes that layer to the NDVI subdirectory.\n",
    "\n",
    "    Args:\n",
    "        d (str): Path of image directory\n",
    "    \"\"\"\n",
    "    im_id = os.path.basename(d)\n",
    "    rgbi = tiff.imread(glob.glob(os.path.join(d, f\"{config.rgbi_dn}/*{config.image_file_ext}\"))[0])\n",
    "    red = rgbi[..., 0] / 255.  # Normalize and convert to float to avoid div by zero issues\n",
    "    nir = rgbi[..., -1] / 255.\n",
    "\n",
    "    # Calculate NDVI\n",
    "    ndvi = (nir.astype(float) - red.astype(float)) / (nir + red)\n",
    "\n",
    "    # Write NDVI to disk\n",
    "    ndvi_dir_path = os.path.join(d, config.ndvi_dn)\n",
    "    if not os.path.exists(ndvi_dir_path):\n",
    "        os.makedirs(ndvi_dir_path)\n",
    "    tiff.imwrite(\n",
    "        os.path.join(\n",
    "            ndvi_dir_path, f\"{im_id}_{config.ndvi_suffix}{config.image_file_ext}\"\n",
    "        ),\n",
    "        ndvi\n",
    "    )\n",
    "    \n",
    "\n",
    "for d in tqdm(im_dirs):\n",
    "    calculate_and_write_ndvi(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load labels, erode, and convert to binary mask (this may take a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erode_labels(d, bool_mask=False):\n",
    "    \"\"\"Takes an image directory, locates the labels image, erodes each tree by 1px,\n",
    "    and returns a 2D image of the resulting eroded labels with their ids or as a\n",
    "    boolean mask.\n",
    "\n",
    "    Args:\n",
    "        d (str): Path of image directory\n",
    "\n",
    "    Returns:\n",
    "        np.array: Eroded labels with ids or as boolean mask. A 2D array of shape\n",
    "        (labels.height, labels.width)\n",
    "    \"\"\"\n",
    "    labels = tiff.imread(\n",
    "        glob.glob(os.path.join(d, config.label_dn, f\"*{config.image_file_ext}\"))[0]\n",
    "    )\n",
    "    labels = label(labels) # Ensure label count == region count\n",
    "    regions = regionprops(labels)  # Get regions with props\n",
    "    eroded_labels = np.zeros_like(labels)\n",
    "    \n",
    "    for i in range(1, labels.max()):\n",
    "        label_i = regions[i].label\n",
    "        eroded = erosion(labels == label_i)\n",
    "        eroded_labels[eroded] = label_i\n",
    "\n",
    "    if bool_mask:\n",
    "        eroded_labels = eroded_labels > 0\n",
    "        \n",
    "    return eroded_labels\n",
    "\n",
    "# Erode the labels to ensure boundaries between each one\n",
    "eroded_labels = np.zeros((len(im_dirs), 512, 512))\n",
    "\n",
    "for i, d in tqdm(enumerate(im_dirs), total=len(im_dirs)):\n",
    "    eroded_labels[i] = erode_labels(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the eroded labels to disk in case you want to use them for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_eroded_labels(eroded_label, d, eroded_dn):\n",
    "    im_id = os.path.basename(d)\n",
    "    \n",
    "    eroded_dir_path = os.path.join(d, eroded_dn)\n",
    "    if not os.path.exists(eroded_dir_path):\n",
    "        os.makedirs(eroded_dir_path)\n",
    "    tiff.imwrite(\n",
    "        os.path.join(\n",
    "            eroded_dir_path, f\"{im_id}_eroded_labels{config.image_file_ext}\"\n",
    "        ),\n",
    "        eroded_label\n",
    "    )\n",
    "\n",
    "for label, d in tqdm(zip(eroded_labels, im_dirs), total=len(im_dirs)):\n",
    "    write_eroded_labels(label, d, \"labels_eroded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "# Acknowledgements:\n",
    "# The code was taken and adapted from Rok Mihevc (rok/unet_weight_map.py).\n",
    "# https://gist.github.com/rok/5f4314ed3c294521456c6afda36a3a50\n",
    "###########################################################################\n",
    "\n",
    "def calculate_ronneberger_weights(labels, wc=None, w0 = 10, sigma = 5):\n",
    "    \"\"\"\n",
    "    Generate weight maps as specified in the U-Net paper\n",
    "    for boolean mask.\n",
    "    \n",
    "    \"U-Net: Convolutional Networks for Biomedical Image Segmentation\"\n",
    "    https://arxiv.org/pdf/1505.04597.pdf\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y: Numpy array\n",
    "        2D array of shape (image_height, image_width) representing boolean (or binary)\n",
    "        mask of objects.\n",
    "    wc: dict\n",
    "        Dictionary of weight classes.\n",
    "    w0: int\n",
    "        Border weight parameter.\n",
    "    sigma: int\n",
    "        Border width parameter.\n",
    "    Returns\n",
    "    -------\n",
    "    Numpy array\n",
    "        Training weights. A 2D array of shape (image_height, image_width).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if mask is boolean or binary mask\n",
    "    if len(np.unique(labels)) == 2:\n",
    "        labels = label(labels)\n",
    "        \n",
    "    no_labels = labels == 0\n",
    "    label_ids = sorted(np.unique(labels))[1:]\n",
    "\n",
    "    if len(label_ids) > 1:\n",
    "        distances = np.zeros((labels.shape[0], labels.shape[1], len(label_ids)))\n",
    "\n",
    "        for i, label_id in enumerate(label_ids):\n",
    "            distances[:,:,i] = distance_transform_edt(labels != label_id)\n",
    "\n",
    "        distances = np.sort(distances, axis=2)\n",
    "        d1 = distances[:,:,0]\n",
    "        d2 = distances[:,:,1]\n",
    "        w = w0 * np.exp(-1/2*((d1 + d2) / sigma)**2) * no_labels\n",
    "        \n",
    "        if wc:\n",
    "            class_weights = np.zeros_like(labels)\n",
    "            for k, v in wc.items():\n",
    "                class_weights[labels == k] = v\n",
    "            w = w + class_weights\n",
    "    else:\n",
    "        w = np.zeros_like(labels)\n",
    "    \n",
    "    return w\n",
    "\n",
    "\n",
    "def calculate_border_weights(labels):\n",
    "    borders = find_boundaries(labels) # Returns a boolean mask of boundaries\n",
    "    borders = np.where(borders, 1, 0)\n",
    "    return borders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and write the weights images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_and_write_weights(d, labels, wt_type=\"ronneberger\"):\n",
    "    im_id = os.path.basename(d)\n",
    "    \n",
    "    if wt_type == \"ronneberger\":\n",
    "        # Set the weights\n",
    "        wc = {\n",
    "            0: 1,  # background\n",
    "            1: 1  # objects\n",
    "        }  \n",
    "        w = calculate_ronneberger_weights(labels, wc)\n",
    "    \n",
    "    elif wt_type == \"border\":\n",
    "        w = calculate_border_weights(labels)\n",
    "    \n",
    "    # Write weights to disk\n",
    "    weights_dir_path = os.path.join(d, config.boundary_weights_dn)\n",
    "    if not os.path.exists(weights_dir_path):\n",
    "        os.makedirs(weights_dir_path)\n",
    "    \n",
    "    tiff.imwrite(\n",
    "            os.path.join(\n",
    "                weights_dir_path,\n",
    "                f\"{im_id}_{config.boundary_suffix}{config.image_file_ext}\",\n",
    "            ),\n",
    "            w,\n",
    "        )\n",
    "\n",
    "\n",
    "for d in tqdm(im_dirs, total=len(im_dirs)):\n",
    "    labels = tiff.imread(\n",
    "        glob.glob(os.path.join(d, config.label_dn, f\"*{config.image_file_ext}\"))[0]\n",
    "    )\n",
    "    calc_and_write_weights(d, labels, wt_type=\"border\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect some random weights files for sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(6, 2, figsize=(10, 30), dpi=250)\n",
    "ax = ax.ravel()\n",
    "\n",
    "for a in ax:\n",
    "    k = np.random.randint(0, len(weight_maps))\n",
    "    im = a.imshow(weight_maps[k], vmin=0, vmax=10)\n",
    "    plt.colorbar(im, ax=a, shrink=0.8)\n",
    "    a.axis(\"off\")\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "71e688b954d902b4a55caabd51fbe36bd50a20d472e1a85360af90ed004984c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
