{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Daniel Lusk, University of Potsdam\n",
    "\n",
    "Inspired by: Ankit Kariryaa ([github repo](https://github.com/ankitkariryaa/An-unexpectedly-large-count-of-trees-in-the-western-Sahara-and-Sahel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "TODO: Write overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started\n",
    "\n",
    "TODO: Write getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-29 14:45:25.143791: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-29 14:45:25.694045: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/miniconda/envs/berlin-trees/lib/\n",
      "2023-04-29 14:45:25.694101: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/miniconda/envs/berlin-trees/lib/\n",
      "2023-04-29 14:45:25.694107: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import matplotlib as mpl\n",
    "\n",
    "from config import Preprocessing\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import erosion\n",
    "from skimage.segmentation import find_boundaries\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from matplotlib.colors import ListedColormap\n",
    "from core.utils import mask_bg\n",
    "\n",
    "import warnings  # ignore annoying warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Magic commands\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "plt.style.use(\"lusk\") # Use custom plot styles\n",
    "\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load configuration and get image directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Preprocessing.Config()\n",
    "im_dirs = glob.glob(os.path.join(config.data_dir_path, \"*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate and write NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_write_ndvi(d):\n",
    "    \"\"\"Takes an image directory, locates the RGBI image, calculates the corresponding\n",
    "    NDVI layer, and writes that layer to the NDVI subdirectory.\n",
    "\n",
    "    Args:\n",
    "        d (str): Path of image directory\n",
    "    \"\"\"\n",
    "    im_id = os.path.basename(d)\n",
    "    rgbi = tiff.imread(glob.glob(os.path.join(d, f\"{config.rgbi_dn}/*{config.image_file_ext}\"))[0])\n",
    "    red = rgbi[..., 0] / 255.  # Normalize and convert to float to avoid div by zero issues\n",
    "    nir = rgbi[..., -1] / 255.\n",
    "\n",
    "    # Calculate NDVI\n",
    "    ndvi = (nir.astype(float) - red.astype(float)) / (nir + red)\n",
    "\n",
    "    # Write NDVI to disk\n",
    "    ndvi_dir_path = os.path.join(d, config.ndvi_dn)\n",
    "    if not os.path.exists(ndvi_dir_path):\n",
    "        os.makedirs(ndvi_dir_path)\n",
    "    tiff.imwrite(\n",
    "        os.path.join(\n",
    "            ndvi_dir_path, f\"{im_id}_{config.ndvi_suffix}{config.image_file_ext}\"\n",
    "        ),\n",
    "        ndvi\n",
    "    )\n",
    "    \n",
    "\n",
    "for d in tqdm(im_dirs):\n",
    "    calculate_and_write_ndvi(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load labels, erode, and convert to binary mask (this may take a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erode_labels(d, bool_mask=False):\n",
    "    \"\"\"Takes an image directory, locates the labels image, erodes each tree by 1px,\n",
    "    and returns a 2D image of the resulting eroded labels with their ids or as a\n",
    "    boolean mask.\n",
    "\n",
    "    Args:\n",
    "        d (str): Path of image directory\n",
    "\n",
    "    Returns:\n",
    "        np.array: Eroded labels with ids or as boolean mask. A 2D array of shape\n",
    "        (labels.height, labels.width)\n",
    "    \"\"\"\n",
    "    labels = tiff.imread(\n",
    "        glob.glob(os.path.join(d, config.label_dn, f\"*{config.image_file_ext}\"))[0]\n",
    "    )\n",
    "    labels = label(labels) # Ensure label count == region count\n",
    "    regions = regionprops(labels)  # Get regions with props\n",
    "    eroded_labels = np.zeros_like(labels)\n",
    "    \n",
    "    for i in range(1, labels.max()):\n",
    "        label_i = regions[i].label\n",
    "        eroded = erosion(labels == label_i)\n",
    "        eroded_labels[eroded] = label_i\n",
    "\n",
    "    if bool_mask:\n",
    "        eroded_labels = eroded_labels > 0\n",
    "        \n",
    "    return eroded_labels\n",
    "\n",
    "# Erode the labels to ensure boundaries between each one\n",
    "eroded_labels = np.zeros((len(im_dirs), 512, 512))\n",
    "\n",
    "for i, d in tqdm(enumerate(im_dirs), total=len(im_dirs)):\n",
    "    eroded_labels[i] = erode_labels(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the eroded labels to disk in case you want to use them for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_eroded_labels(eroded_label, d, eroded_dn):\n",
    "    im_id = os.path.basename(d)\n",
    "    \n",
    "    eroded_dir_path = os.path.join(d, eroded_dn)\n",
    "    if not os.path.exists(eroded_dir_path):\n",
    "        os.makedirs(eroded_dir_path)\n",
    "    tiff.imwrite(\n",
    "        os.path.join(\n",
    "            eroded_dir_path, f\"{im_id}_eroded_labels{config.image_file_ext}\"\n",
    "        ),\n",
    "        eroded_label\n",
    "    )\n",
    "\n",
    "for label, d in tqdm(zip(eroded_labels, im_dirs), total=len(im_dirs)):\n",
    "    write_eroded_labels(label, d, \"labels_eroded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "# Acknowledgements:\n",
    "# The code was taken and adapted from Rok Mihevc (rok/unet_weight_map.py).\n",
    "# https://gist.github.com/rok/5f4314ed3c294521456c6afda36a3a50\n",
    "###########################################################################\n",
    "\n",
    "def calculate_ronneberger_weights(labels, wc=None, w0 = 10, sigma = 5):\n",
    "    \"\"\"\n",
    "    Generate weight maps as specified in the U-Net paper\n",
    "    for boolean mask.\n",
    "    \n",
    "    \"U-Net: Convolutional Networks for Biomedical Image Segmentation\"\n",
    "    https://arxiv.org/pdf/1505.04597.pdf\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y: Numpy array\n",
    "        2D array of shape (image_height, image_width) representing boolean (or binary)\n",
    "        mask of objects.\n",
    "    wc: dict\n",
    "        Dictionary of weight classes.\n",
    "    w0: int\n",
    "        Border weight parameter.\n",
    "    sigma: int\n",
    "        Border width parameter.\n",
    "    Returns\n",
    "    -------\n",
    "    Numpy array\n",
    "        Training weights. A 2D array of shape (image_height, image_width).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if mask is boolean or binary mask\n",
    "    if len(np.unique(labels)) == 2:\n",
    "        labels = label(labels)\n",
    "        \n",
    "    no_labels = labels == 0\n",
    "    label_ids = sorted(np.unique(labels))[1:]\n",
    "\n",
    "    if len(label_ids) > 1:\n",
    "        distances = np.zeros((labels.shape[0], labels.shape[1], len(label_ids)))\n",
    "\n",
    "        for i, label_id in enumerate(label_ids):\n",
    "            distances[:,:,i] = distance_transform_edt(labels != label_id)\n",
    "\n",
    "        distances = np.sort(distances, axis=2)\n",
    "        d1 = distances[:,:,0]\n",
    "        d2 = distances[:,:,1]\n",
    "        w = w0 * np.exp(-1/2*((d1 + d2) / sigma)**2) * no_labels\n",
    "        \n",
    "        if wc:\n",
    "            class_weights = np.zeros_like(labels)\n",
    "            for k, v in wc.items():\n",
    "                class_weights[labels == k] = v\n",
    "            w = w + class_weights\n",
    "    else:\n",
    "        w = np.zeros_like(labels)\n",
    "    \n",
    "    return w\n",
    "\n",
    "\n",
    "def calculate_border_weights(labels):\n",
    "    borders = find_boundaries(labels) # Returns a boolean mask of boundaries\n",
    "    borders = np.where(borders, 1, 0)\n",
    "    return borders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and write the weights images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_and_write_weights(d, labels, wt_type=\"ronneberger\"):\n",
    "    im_id = os.path.basename(d)\n",
    "    \n",
    "    if wt_type == \"ronneberger\":\n",
    "        # Set the weights\n",
    "        wc = {\n",
    "            0: 1,  # background\n",
    "            1: 1  # objects\n",
    "        }  \n",
    "        w = calculate_ronneberger_weights(labels, wc)\n",
    "    \n",
    "    elif wt_type == \"border\":\n",
    "        w = calculate_border_weights(labels)\n",
    "    \n",
    "    # Write weights to disk\n",
    "    weights_dir_path = os.path.join(d, config.boundary_weights_dn)\n",
    "    if not os.path.exists(weights_dir_path):\n",
    "        os.makedirs(weights_dir_path)\n",
    "    \n",
    "    tiff.imwrite(\n",
    "            os.path.join(\n",
    "                weights_dir_path,\n",
    "                f\"{im_id}_{config.boundary_suffix}{config.image_file_ext}\",\n",
    "            ),\n",
    "            w,\n",
    "        )\n",
    "\n",
    "\n",
    "for d in tqdm(im_dirs, total=len(im_dirs)):\n",
    "    labels = tiff.imread(\n",
    "        glob.glob(os.path.join(d, config.label_dn, f\"*{config.image_file_ext}\"))[0]\n",
    "    )\n",
    "    calc_and_write_weights(d, labels, wt_type=\"border\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect some random weights files for sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(6, 2, figsize=(10, 30), dpi=250)\n",
    "# ax = ax.ravel()\n",
    "\n",
    "# for a in ax:\n",
    "#     k = np.random.randint(0, len(weight_maps))\n",
    "#     im = a.imshow(weight_maps[k], vmin=0, vmax=10)\n",
    "#     plt.colorbar(im, ax=a, shrink=0.8)\n",
    "#     a.axis(\"off\")\n",
    "# plt.show();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data inspection\n",
    "\n",
    "Get total tree counts in training and validation sets (watershed and hand-labeled sets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_fns = glob.glob(\"../../data/dap05/*loose*.tif\")\n",
    "\n",
    "train_tree_cts = np.zeros((len(train_label_fns)))\n",
    "\n",
    "for i, fn in enumerate(train_label_fns):\n",
    "    labels = tiff.imread(fn)\n",
    "    ct = np.count_nonzero(np.unique(labels))\n",
    "    train_tree_cts[i] = ct\n",
    "\n",
    "print(\"Total number of trees in training set:\", train_tree_cts.astype(int).sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi-automated labels vs hand labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patch:\n",
    "    def __init__(self, dirname, labels_only=False):\n",
    "        dirs = sorted(glob.glob(dirname))\n",
    "        for d in dirs:\n",
    "            dname = os.path.basename(d)\n",
    "            fname = glob.glob(os.path.join(d, \"*.tif\"))[0]\n",
    "            if not labels_only:\n",
    "                im = tiff.imread(fname)\n",
    "                setattr(self, dname, im)\n",
    "            else:\n",
    "                if dname == \"labels\":\n",
    "                    im = tiff.imread(fname)\n",
    "                    setattr(self, dname, im)\n",
    "\n",
    "# Colormap\n",
    "rainbow = mpl.colormaps[\"rainbow\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_hand_dir = \"../../data/dap05/combined/512/393_5823_2020_01_01/*\"\n",
    "samp_ws_dir = \"../../data/dap05/combined/512/Friedrichshain_1_2/*\"\n",
    "\n",
    "hand = Patch(samp_hand_dir)\n",
    "auto = Patch(samp_ws_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "cmap = ListedColormap(rainbow(np.random.random(len(np.unique(hand.labels)))))\n",
    "\n",
    "patches = [auto, hand]\n",
    "titles = [ \"Train\", \"Val/Test\"]\n",
    "\n",
    "for patch, title, ax in zip(patches, titles, axs):\n",
    "    ax.imshow(patch.rgbi[..., :3])\n",
    "    ax.imshow(mask_bg(patch.labels), cmap=cmap, alpha=0.4)\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.savefig(os.path.join(config.figures_dir, \"hand-vs-auto-labels.png\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eroded vs non-eroded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "cmap = ListedColormap(rainbow(np.random.random(len(np.unique(auto.labels)))))\n",
    "\n",
    "auto_rgbi = auto.rgbi[..., :3]\n",
    "patches = [auto.labels, auto.labels_eroded]\n",
    "titles = [\"ORIG\", \"ERODED\"]\n",
    "\n",
    "for patch, title, ax in zip(patches, titles, axs):\n",
    "    ax.imshow(auto_rgbi)\n",
    "    ax.imshow(mask_bg(patch), cmap=cmap, alpha=0.4)\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "plt.savefig(os.path.join(config.figures_dir, \"orig-vs-eroded-labels.png\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "fig, axs = plt.subplots(1, 4)\n",
    "cmap = ListedColormap(rainbow(np.random.random(len(np.unique(auto.labels)))))\n",
    "\n",
    "rgbi = hand.rgbi[..., :3]\n",
    "# patches = [hand.weights, hand.border_weights]\n",
    "titles = [\"Labels\", \"RONN\", \"BOUNDS10\", \"BORD10\"]\n",
    "\n",
    "ronn = hand.weights.copy()\n",
    "bound = hand.weights.copy()\n",
    "bord = hand.border_weights.copy()\n",
    "bound_thr = 2\n",
    "\n",
    "ronn[np.where(ronn == 0)] = 0.5\n",
    "bound[np.where(bound == 0)] = 0.5\n",
    "bound[np.where((bound < bound_thr) & (bound > 0.5))] = 1\n",
    "bound[np.where(bound >= bound_thr)] = 10\n",
    "bord = np.where(bord >= 1, 10., 1.)\n",
    "bg = np.where(hand.labels > 0, np.nan, 1)\n",
    "bord[np.where(bg == 1)] = 1.5\n",
    "# bord[np.where(bord > 2)] = 10.\n",
    "patches = [hand.labels > 0, ronn, bound, bord]\n",
    "\n",
    "for patch, title, ax in zip(patches, titles, axs):\n",
    "    # ax.imshow(auto_rgbi)\n",
    "    im = ax.imshow(mask_bg(patch), cmap=\"viridis\")\n",
    "    if title == \"RONN\":\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.new_vertical(size=\"5%\", pad=-0.05, pack_start=True)\n",
    "        fig.add_axes(cax)\n",
    "        plt.colorbar(im, cax=cax, orientation=\"horizontal\")\n",
    "    # if title == \"BORD10\":\n",
    "    #     ax.imshow(bg, cmap=\"viridis\")\n",
    "    ax.set_title(title, fontsize=10)\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "plt.savefig(os.path.join(config.figures_dir, \"weight_maps.png\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic vs instance segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "cmap = ListedColormap(rainbow(np.random.random(len(np.unique(hand.labels)))))\n",
    "\n",
    "patches = [hand.labels]\n",
    "titles = [\"Semantic Segmentation\", \"Instance Segmentation\"]\n",
    "\n",
    "for title, ax in zip(titles, axs):\n",
    "    # ax.imshow(auto_rgbi)\n",
    "    if title == \"Semantic Segmentation\":\n",
    "        im = ax.imshow(mask_bg(hand.labels > 0))\n",
    "    else:\n",
    "        im = ax.imshow(mask_bg(hand.labels), cmap=cmap, alpha=1)\n",
    "\n",
    "    ax.set_title(title, fontsize=12)\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "plt.savefig(os.path.join(config.figures_dir, \"semantic-vs-instance.png\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get label/bg percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dirs = glob.glob(\"../../data/dap05/combined/512/*\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand = Patch(samp_hand_dir)\n",
    "auto = Patch(samp_ws_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "71e688b954d902b4a55caabd51fbe36bd50a20d472e1a85360af90ed004984c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
